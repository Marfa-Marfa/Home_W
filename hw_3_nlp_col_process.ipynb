{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jR4t27flyi6"
      },
      "source": [
        "# Домашнее задание NLP-3\n",
        "Что в векторе твоем?\n",
        "\n",
        "#### Цель:\n",
        "В этом ДЗ вы освоите работу с предобученными векторными представлениями.\n",
        "\n",
        "#### Описание/Пошаговая инструкция выполнения домашнего задания:\n",
        "В качестве данных возьмите либо датасет, собранный в первом занятии (предпочтительно), либо скачайте данные с отзывами на фильмы с сайта IMDB (https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews), в которых для каждого отзыва поставлена семантическая оценка - \"позитивный\" или \"негативный\".\n",
        "\n",
        "1) Разбейте собранные данные на train/test, отложив 20-30% наблюдений для тестирования.\n",
        "2) Примените tf-idf преобразование для текстового описания. Используйте как отдельные токены, так и биграммы, отсейте стоп-слова, а также слова, которые встречаются слишком редко или слишком часто (параметры min/max_df), не забудьте убрать l2 регуляризацию, которая по умолчанию включена.\n",
        "3) Обучите random forest или градиентный бустинг (LightGBM или catboost) на полученных векторах и подберите оптимальную комбинацию гиперпараметров с помощью GridSearch\n",
        "4) Теперь воспользуйтесь предобученными word2vec / fasttext эмбеддингами для векторизации текста. Векторизуйте тексты с помощью метода word2vec/fasttext c весами tf-idf\n",
        "Совет: для текстов на русском языке можно взять предобученные эмбеддинги с сайта rusvectores https://rusvectores.org/ru/models/ (вам подходят эмбеддинги с параметром тэгсет НЕТ). Для английского языка можете воспользоваться word2vec, обученными на Google News\n",
        "5) Повторите эксперимент из пункта 3 с использованием полученных в пункте 4 векторов\n",
        "\n",
        "#### Критерии оценки:\n",
        "Разбиение на train/test - 1 балл  \\\n",
        "Предобработка текста при помощи tf-idf - 2 балла  \\\n",
        "Обучение модели на tf-idf векторах - 2 балла  \\\n",
        "Преобработка текста при помощи преобученных эмбеддингов word2vec/fasttext - 3 балла  \\\n",
        "Обучение модели на предобученных эмбеддингах - 2 балла"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTyNU1tml3to"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "from sklearn.metrics import *\n",
        "tqdm.pandas()\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from lightgbm import LGBMClassifier\n",
        "import lightgbm as lgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "VoV-sYVllnrf",
        "outputId": "2cbc12e8-41d3-4627-c147-8179bbfafc0b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2ab45482-4461-4a90-9549-489e6554cfb5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ab45482-4461-4a90-9549-489e6554cfb5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2ab45482-4461-4a90-9549-489e6554cfb5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2ab45482-4461-4a90-9549-489e6554cfb5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-01f1d476-3ef7-4503-8685-00331737c6f9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-01f1d476-3ef7-4503-8685-00331737c6f9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-01f1d476-3ef7-4503-8685-00331737c6f9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 50000,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 49582,\n        \"samples\": [\n          \"\\\"Soul Plane\\\" is a horrible attempt at comedy that only should appeal people with thick skulls, bloodshot eyes and furry pawns. <br /><br />The plot is not only incoherent but also non-existent, acting is mostly sub sub-par with a gang of highly moronic and dreadful characters thrown in for bad measure, jokes are often spotted miles ahead and almost never even a bit amusing. This movie lacks any structure and is full of racial stereotypes that must have seemed old even in the fifties, the only thing it really has going for it is some pretty ladies, but really, if you want that you can rent something from the \\\"Adult\\\" section. OK?<br /><br />I can hardly see anything here to recommend since you'll probably have a lot a better and productive time chasing rats with a sledgehammer or inventing waterproof teabags or whatever.<br /><br />2/10\",\n          \"Guest from the Future tells a fascinating story of time travel, friendship, battle of good and evil -- all with a small budget, child actors, and few special effects. Something for Spielberg and Lucas to learn from. ;) A sixth-grader Kolya \\\"Nick\\\" Gerasimov finds a time machine in the basement of a decrepit building and travels 100 years into the future. He discovers a near-perfect, utopian society where robots play guitars and write poetry, everyone is kind to each other and people enjoy everything technology has to offer. Alice is the daughter of a prominent scientist who invented a device called Mielophone that allows to read minds of humans and animals. The device can be put to both good and bad use, depending on whose hands it falls into. When two evil space pirates from Saturn who want to rule the universe attempt to steal Mielophone, it falls into the hands of 20th century school boy Nick. With the pirates hot on his tracks, he travels back to his time, followed by the pirates, and Alice. Chaos, confusion and funny situations follow as the luckless pirates try to blend in with the earthlings. Alice enrolls in the same school Nick goes to and demonstrates superhuman abilities in PE class. The catch is, Alice doesn't know what Nick looks like, while the pirates do. Also, the pirates are able to change their appearance and turn literally into anyone. (Hmm, I wonder if this is where James Cameron got the idea for Terminator...) Who gets to Nick -- and Mielophone -- first? Excellent plot, non-stop adventures, and great soundtrack. I wish Hollywood made kid movies like this one...\",\n          \"\\\"National Treasure\\\" (2004) is a thoroughly misguided hodge-podge of plot entanglements that borrow from nearly every cloak and dagger government conspiracy clich\\u00e9 that has ever been written. The film stars Nicholas Cage as Benjamin Franklin Gates (how precious is that, I ask you?); a seemingly normal fellow who, for no other reason than being of a lineage of like-minded misguided fortune hunters, decides to steal a 'national treasure' that has been hidden by the United States founding fathers. After a bit of subtext and background that plays laughably (unintentionally) like Indiana Jones meets The Patriot, the film degenerates into one misguided whimsy after another \\u0096 attempting to create a 'Stanley Goodspeed' regurgitation of Nicholas Cage and launch the whole convoluted mess forward with a series of high octane, but disconnected misadventures.<br /><br />The relevancy and logic to having George Washington and his motley crew of patriots burying a king's ransom someplace on native soil, and then, going through the meticulous plan of leaving clues scattered throughout U.S. currency art work, is something that director Jon Turteltaub never quite gets around to explaining. Couldn't Washington found better usage for such wealth during the start up of the country? Hence, we are left with a mystery built on top of an enigma that is already on shaky ground by the time Ben appoints himself the new custodian of this untold wealth. Ben's intentions are noble \\u0096 if confusing. He's set on protecting the treasure. For who and when?\\u0085your guess is as good as mine.<br /><br />But there are a few problems with Ben's crusade. First up, his friend, Ian Holmes (Sean Bean) decides that he can't wait for Ben to make up his mind about stealing the Declaration of Independence from the National Archives (oh, yeah \\u0096 brilliant idea!). Presumably, the back of that famous document holds the secret answer to the ultimate fortune. So Ian tries to kill Ben. The assassination attempt is, of course, unsuccessful, if overly melodramatic. It also affords Ben the opportunity to pick up, and pick on, the very sultry curator of the archives, Abigail Chase (Diane Kruger). She thinks Ben is clearly a nut \\u0096 at least at the beginning. But true to action/romance form, Abby's resolve melts quicker than you can say, \\\"is that the Hope Diamond?\\\" The film moves into full X-File-ish mode, as the FBI, mistakenly believing that Ben is behind the theft, retaliate in various benign ways that lead to a multi-layering of action sequences reminiscent of Mission Impossible meets The Fugitive. Honestly, don't those guys ever get 'intelligence' information that is correct? In the final analysis, \\\"National Treasure\\\" isn't great film making, so much as it's a patchwork rehash of tired old bits from other movies, woven together from scraps, the likes of which would make IL' Betsy Ross blush.<br /><br />The Buena Vista DVD delivers a far more generous treatment than this film is deserving of. The anamorphic widescreen picture exhibits a very smooth and finely detailed image with very rich colors, natural flesh tones, solid blacks and clean whites. The stylized image is also free of blemishes and digital enhancements. The audio is 5.1 and delivers a nice sonic boom to your side and rear speakers with intensity and realism. Extras include a host of promotional junket material that is rather deep and over the top in its explanation of how and why this film was made. If only, as an audience, we had had more clarification as to why Ben and co. were chasing after an illusive treasure, this might have been one good flick. Extras conclude with the theatrical trailer, audio commentary and deleted scenes. Not for the faint-hearted \\u0096 just the thick-headed.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df = pd.read_csv('IMDB Dataset.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWmtqHxBhYeB",
        "outputId": "a36e37d9-d830-4a5d-bc05-62cb5e5ac806"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kagtfP6nyDi",
        "outputId": "0c2f1054-0105-4020-d648-d9d1cf7ea7e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sentiment\n",
              "positive    25000\n",
              "negative    25000\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df['sentiment'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hT4sRvCchYeC"
      },
      "source": [
        "У нас сбалансированный по классам датасет"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qX2d0bdHhYeC"
      },
      "source": [
        "# 1. Предобработка текста"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ecilcCTqO9W"
      },
      "outputs": [],
      "source": [
        "# Удаляем пунктуацию\n",
        "import string\n",
        "spec_chars = string.punctuation + '\\d\\n\\xa0«»\\t—…'\n",
        "\n",
        "df['clear'] = df['review'].str.lower().str.replace(f'[{spec_chars}]', '', regex=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJAC6qDihYeD"
      },
      "source": [
        "## 1.1.Токенизация текста с использованием отдельных токенов и биграмм."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioMAyp_OrDWI",
        "outputId": "605ec406-335e-4469-bb93-ed8f2c30d4c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "100%|██████████| 50000/50000 [00:47<00:00, 1048.01it/s]\n"
          ]
        }
      ],
      "source": [
        "# Загружаем токенизатор\n",
        "\n",
        "from nltk.tokenize import word_tokenize  # импортируем функцию 'word_tokenize' из пакета 'nltk.tokenize'.\n",
        "                # которая выполняет токенизацию текста, разбивая его на отдельные слова.\n",
        "\n",
        "nltk.download('punkt') # загружаем пакет 'punkt' из NLTK.'punkt' - набор правил для токенизации текста на английском языке.\n",
        "  # Он определяет, как разделять текст на отдельные слова, учитывая пробелы, знаки препинания, пунктуацию и другие элементы.\n",
        "\n",
        "df['tokens'] = df['clear'].progress_apply(word_tokenize) #новый столбец в DataFrame, который будет содержать результат\n",
        "                                                         # токенизации"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEOQimgHhYeD"
      },
      "source": [
        "## 1.2.Стемминг и отсеивание стоп-слов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xG5YwouYoFMs",
        "outputId": "74ebacc7-2f8a-4898-a41e-72326e5d577b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "100%|██████████| 50000/50000 [00:01<00:00, 33529.86it/s]\n",
            "100%|██████████| 50000/50000 [00:11<00:00, 4187.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 12.3 s, sys: 171 ms, total: 12.5 s\n",
            "Wall time: 13.5 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Применяем стемминг (т.к. англ.язык) и удаляем стоп-слова\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stops = set(stopwords.words('english'))\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "\n",
        "df['stem'] = df['tokens'].progress_apply(lambda x: ' '.join([i for i in x if i not in stops])).progress_apply(stemmer.stem)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "id": "fjCa1SAhhYeE",
        "outputId": "86dc6fbb-bdae-4418-f12f-00027cc13c78"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review sentiment  \\\n",
              "0  One of the other reviewers has mentioned that ...  positive   \n",
              "1  A wonderful little production. <br /><br />The...  positive   \n",
              "2  I thought this was a wonderful way to spend ti...  positive   \n",
              "3  Basically there's a family where a little boy ...  negative   \n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
              "\n",
              "                                               clear  \\\n",
              "0  one of the other reviewers has mentioned that ...   \n",
              "1  a wonderful little production br br the filmin...   \n",
              "2  i thought this was a wonderful way to spend ti...   \n",
              "3  basically theres a family where a little boy j...   \n",
              "4  petter matteis love in the time of money is a ...   \n",
              "\n",
              "                                              tokens  \\\n",
              "0  [one, of, the, other, reviewers, has, mentione...   \n",
              "1  [a, wonderful, little, production, br, br, the...   \n",
              "2  [i, thought, this, was, a, wonderful, way, to,...   \n",
              "3  [basically, theres, a, family, where, a, littl...   \n",
              "4  [petter, matteis, love, in, the, time, of, mon...   \n",
              "\n",
              "                                                stem  \n",
              "0  one reviewers mentioned watching oz episode yo...  \n",
              "1  wonderful little production br br filming tech...  \n",
              "2  thought wonderful way spend time hot summer we...  \n",
              "3  basically theres family little boy jake thinks...  \n",
              "4  petter matteis love time money visually stunni...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ede064af-ac06-4617-b43d-245d2e65ef0d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>clear</th>\n",
              "      <th>tokens</th>\n",
              "      <th>stem</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>one of the other reviewers has mentioned that ...</td>\n",
              "      <td>[one, of, the, other, reviewers, has, mentione...</td>\n",
              "      <td>one reviewers mentioned watching oz episode yo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "      <td>a wonderful little production br br the filmin...</td>\n",
              "      <td>[a, wonderful, little, production, br, br, the...</td>\n",
              "      <td>wonderful little production br br filming tech...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "      <td>i thought this was a wonderful way to spend ti...</td>\n",
              "      <td>[i, thought, this, was, a, wonderful, way, to,...</td>\n",
              "      <td>thought wonderful way spend time hot summer we...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>basically theres a family where a little boy j...</td>\n",
              "      <td>[basically, theres, a, family, where, a, littl...</td>\n",
              "      <td>basically theres family little boy jake thinks...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "      <td>petter matteis love in the time of money is a ...</td>\n",
              "      <td>[petter, matteis, love, in, the, time, of, mon...</td>\n",
              "      <td>petter matteis love time money visually stunni...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ede064af-ac06-4617-b43d-245d2e65ef0d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ede064af-ac06-4617-b43d-245d2e65ef0d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ede064af-ac06-4617-b43d-245d2e65ef0d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-df57ddcb-2a2b-4b6b-ba8f-7d7b2d7cd90c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-df57ddcb-2a2b-4b6b-ba8f-7d7b2d7cd90c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-df57ddcb-2a2b-4b6b-ba8f-7d7b2d7cd90c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 50000,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 49582,\n        \"samples\": [\n          \"\\\"Soul Plane\\\" is a horrible attempt at comedy that only should appeal people with thick skulls, bloodshot eyes and furry pawns. <br /><br />The plot is not only incoherent but also non-existent, acting is mostly sub sub-par with a gang of highly moronic and dreadful characters thrown in for bad measure, jokes are often spotted miles ahead and almost never even a bit amusing. This movie lacks any structure and is full of racial stereotypes that must have seemed old even in the fifties, the only thing it really has going for it is some pretty ladies, but really, if you want that you can rent something from the \\\"Adult\\\" section. OK?<br /><br />I can hardly see anything here to recommend since you'll probably have a lot a better and productive time chasing rats with a sledgehammer or inventing waterproof teabags or whatever.<br /><br />2/10\",\n          \"Guest from the Future tells a fascinating story of time travel, friendship, battle of good and evil -- all with a small budget, child actors, and few special effects. Something for Spielberg and Lucas to learn from. ;) A sixth-grader Kolya \\\"Nick\\\" Gerasimov finds a time machine in the basement of a decrepit building and travels 100 years into the future. He discovers a near-perfect, utopian society where robots play guitars and write poetry, everyone is kind to each other and people enjoy everything technology has to offer. Alice is the daughter of a prominent scientist who invented a device called Mielophone that allows to read minds of humans and animals. The device can be put to both good and bad use, depending on whose hands it falls into. When two evil space pirates from Saturn who want to rule the universe attempt to steal Mielophone, it falls into the hands of 20th century school boy Nick. With the pirates hot on his tracks, he travels back to his time, followed by the pirates, and Alice. Chaos, confusion and funny situations follow as the luckless pirates try to blend in with the earthlings. Alice enrolls in the same school Nick goes to and demonstrates superhuman abilities in PE class. The catch is, Alice doesn't know what Nick looks like, while the pirates do. Also, the pirates are able to change their appearance and turn literally into anyone. (Hmm, I wonder if this is where James Cameron got the idea for Terminator...) Who gets to Nick -- and Mielophone -- first? Excellent plot, non-stop adventures, and great soundtrack. I wish Hollywood made kid movies like this one...\",\n          \"\\\"National Treasure\\\" (2004) is a thoroughly misguided hodge-podge of plot entanglements that borrow from nearly every cloak and dagger government conspiracy clich\\u00e9 that has ever been written. The film stars Nicholas Cage as Benjamin Franklin Gates (how precious is that, I ask you?); a seemingly normal fellow who, for no other reason than being of a lineage of like-minded misguided fortune hunters, decides to steal a 'national treasure' that has been hidden by the United States founding fathers. After a bit of subtext and background that plays laughably (unintentionally) like Indiana Jones meets The Patriot, the film degenerates into one misguided whimsy after another \\u0096 attempting to create a 'Stanley Goodspeed' regurgitation of Nicholas Cage and launch the whole convoluted mess forward with a series of high octane, but disconnected misadventures.<br /><br />The relevancy and logic to having George Washington and his motley crew of patriots burying a king's ransom someplace on native soil, and then, going through the meticulous plan of leaving clues scattered throughout U.S. currency art work, is something that director Jon Turteltaub never quite gets around to explaining. Couldn't Washington found better usage for such wealth during the start up of the country? Hence, we are left with a mystery built on top of an enigma that is already on shaky ground by the time Ben appoints himself the new custodian of this untold wealth. Ben's intentions are noble \\u0096 if confusing. He's set on protecting the treasure. For who and when?\\u0085your guess is as good as mine.<br /><br />But there are a few problems with Ben's crusade. First up, his friend, Ian Holmes (Sean Bean) decides that he can't wait for Ben to make up his mind about stealing the Declaration of Independence from the National Archives (oh, yeah \\u0096 brilliant idea!). Presumably, the back of that famous document holds the secret answer to the ultimate fortune. So Ian tries to kill Ben. The assassination attempt is, of course, unsuccessful, if overly melodramatic. It also affords Ben the opportunity to pick up, and pick on, the very sultry curator of the archives, Abigail Chase (Diane Kruger). She thinks Ben is clearly a nut \\u0096 at least at the beginning. But true to action/romance form, Abby's resolve melts quicker than you can say, \\\"is that the Hope Diamond?\\\" The film moves into full X-File-ish mode, as the FBI, mistakenly believing that Ben is behind the theft, retaliate in various benign ways that lead to a multi-layering of action sequences reminiscent of Mission Impossible meets The Fugitive. Honestly, don't those guys ever get 'intelligence' information that is correct? In the final analysis, \\\"National Treasure\\\" isn't great film making, so much as it's a patchwork rehash of tired old bits from other movies, woven together from scraps, the likes of which would make IL' Betsy Ross blush.<br /><br />The Buena Vista DVD delivers a far more generous treatment than this film is deserving of. The anamorphic widescreen picture exhibits a very smooth and finely detailed image with very rich colors, natural flesh tones, solid blacks and clean whites. The stylized image is also free of blemishes and digital enhancements. The audio is 5.1 and delivers a nice sonic boom to your side and rear speakers with intensity and realism. Extras include a host of promotional junket material that is rather deep and over the top in its explanation of how and why this film was made. If only, as an audience, we had had more clarification as to why Ben and co. were chasing after an illusive treasure, this might have been one good flick. Extras conclude with the theatrical trailer, audio commentary and deleted scenes. Not for the faint-hearted \\u0096 just the thick-headed.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clear\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 49581,\n        \"samples\": [\n          \"poorly done political actioner badly photographed acted and directed every single scene is underlighted including those very few that are shot during the daytime it doesnt matter what the location is at an important conference in the white house no lights are on and the only available lighting is a gloomy blue that is filtered through a few windows the primier of china conducts an earthshattering phone conversation under conditions of such intense chiaroscuro that he should be contemplating a bust of homer in a rembrandt painting honest its as if he had a tiny spotlight on his face and was otherwise in total darkness the slow motion deaths are by now obligatory in any illthoughtout moviebr br roy scheider and maria conchita alonzo do well by their roles but scheider is rarely on screen the other performances are dismissable there is a pretty oriental woman in a short tight skirt who totes a gun and is right out of a bond movie whos accent suggests a childhood spent in basset nebraska and who should have remained the model she probably started out as whoever plays the surviving secret service agent aboard the cruise ship was probably picked for the part because he looked most like johnny depp not because of any display of talent the chinese villains representing both taiwan and mainland china hiss and grin as they threaten the heroes br br the script is pretty awful recycled from other better films there is a lot of shooting aboard the ship and practically everyone winds up mincemeat two thirds of the way through the ship explodes into the expected series of fireballs then the movie splits into two related parts part one another shootout this time in a waterfront warehouse part two an exchange between the vice president now acting president and the oily chinese premiere lifted out of both dr strangelove and fail safe we unwittingly launch our missiles they launch theirs in retaliation we cannot convince them that our launch was accidental even though we offer to help them destroy our own missiles there is even the george c scott walter matthau general who argues that their nucular armory cant match ours so we should hit them with everything weve got more fireballs br br the end comes none too soon\",\n          \"not good mostly because you dont give a damn about what happens to all these people some comments   i am tired of seeing governesses who never talk to their pupils never teach them anything and take a tired and annoyed look whenever the said pupil who of course has been won over in the space of  seconds says something  fine so rosina has a father complex and therefore is attracted to her employer but charles is completely different in all aspects from her father  if anything henry is much closer as a sensual exalted person  how could you ever believe that she would be more attracted to tom wilkinson than to rhys meyer  hard to believe if she had been in fact raised as a deeply religious girl that she would be so careless about sleeping with a gentile after knowing him for  minutesbr br some good things about the film  at least she didnt end up pregnant not knowing who the father was the whole description of life in the jewish community in london is good\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokens\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stem\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 49578,\n        \"samples\": [\n          \"since frame number know good guy suit necktie doomed luck sorte nula believes music car radio dubious talk best friend company associate taking parts unknown desert road alberto wished simply left alone take flight abroad next day well someone left guessing br br film goes long way \\u0096 thatll find short \\u0096 closing scene man hearing music cab airport number lucky people found different ways story dying born others falling harrowing distress time hes really doomed film sort oneman show director fernando fragata left sound recording special effects competent people typically reject portuguese films due sound problems unclear speech recording must go searching topics criticize time car crash isnt spoilers film clever makes great scene apparently done cheap equipment us studios take notice may spare dollar two hiding competent portuguese directors br br rest done fragata script dialogue camera work editing part dialogue adlibbed must congratulated acting direction casting mostly inexperienced actors large number nonspeaking parts credited people used music video clip making used extensively films promotional trailer cast dozen actors actresses ten relevant persons huge number relationships \\u0096 revealed stepbystep thrilling suspenseful way reminiscent best genre authors alfred hitchcock qv claude chabrol qv come mind catandmouse play director public nature charactersbr br recommend thriller comedy portuguese language speakers film gets decent translation colloquial dialogue anyone abroad enjoys genr\",\n          \"dentist really good thriller pretty disturbing think agree chances running psycho dentist much bigger running monsters vampires zombies thats exactly movie scary film youll probably think dentist times whether hes capable thingsyou better pray wife doesnt cheat thats story respected dentist la snaps finds wife cheating poolboy must greatest profession world way poolboys always take advantage housewives husband work dentist dr feinstone thing taking revenge cant concentrate patients anymore couple get hurt things arent made easier dentist hes chased annoying taxcontroller curious cop suspicious staff member one point dr feinstone cant take anymore hes wife everyone comes near dentist written directed brian yuzna cowritten stuart gordon take recommendation persons already gave us great horror movies personal favorites mine like reanimator beyond society dentist succeed bring entertaining chilling thriller film came right time actually decade hadnt brought us many great horror films far im saying masterpiece nice change corbin bensen great dentist obsessed hygiene remember mostly comedy drama actor sure handle psychotic character rest cast good work woman plays feinstones wife really attractive also great see ken foree acting actor time favorite movie dawn dead plays cop film yuzna casted beyond years ago thank dont recommend movie everyone weak stomach ill advise skip watch youll enjoy much youll disgustedbut thats extra reason think since really freaked watching film great topic handle genre yuzna great way bad film followed completely unnecessary sequel humble opinion dentist\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRBV049MhYeF"
      },
      "source": [
        "## 1.4. Модель векторизации текста tf-idf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5e8jpvupqOE"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYVfQ4KOhYeG"
      },
      "outputs": [],
      "source": [
        "# Преобразуем текстовые данные в векторы чисел\n",
        "# TF-IDF - это метод, который присваивает весовые коэффициенты словам в тексте, чтобы отразить их важность.\n",
        "# Слова, которые часто встречаются в конкретном документе, но реже встречаются в других документах,\n",
        "# получают более высокие весовые коэффициенты.\n",
        "vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1,2), norm=None, min_df=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vg6U0jeMhYeG"
      },
      "source": [
        "Сохраним в Х - признак, а в у - целевую переменную."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDWRCVD3hYeG"
      },
      "outputs": [],
      "source": [
        "X = df['stem']\n",
        "y = df['sentiment']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F075rK13hYeG"
      },
      "source": [
        "Разобьем выборку на train/test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efXb-rUThYeH",
        "outputId": "88535ef5-780a-469e-c0fb-a0e6a5d7ca4b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((35000,), (15000,), (35000,), (15000,))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                          test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psRKta5vxrA5"
      },
      "outputs": [],
      "source": [
        "X_train = vectorizer.fit_transform(X_train) # Преобразуем текстовые данные в выборке'X_train' в векторы TF-IDF,\n",
        "    # обучаем 'TfidfVectorizer' на данных из 'X_train' и преобразуем эти данные в матрицу TF-IDF.\n",
        "X_test = vectorizer.transform(X_test) # Преобразует текстовые данные в тестовой выборке 'X_test' в векторы TF-IDF.\n",
        "  #Важно использовать 'transform'  (а не `fit_transform`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gixdgKuywpZM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "c64395cc-d4fe-45ad-9f42-86bc2924942f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nВажно, чтобы  'LabelEncoder'  был  обучен  только  на  тренировочных  данных  (используя  'le.fit(y_train)). \\nЗатем  можно  использовать  'le.transform()'  для  преобразования  тестовых  меток  'y_test'.  \\nЭто  гарантирует,  что  тестовые  метки  будут  преобразованы  в  те же  числовые  значения,  \\nкоторые  были  использованы  для  тренировки  модели.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "le = LabelEncoder() # 'LabelEncoder'  преобразуем  текстовые  метки  в  числовые  значения\n",
        "le.fit(y_train) #  Обучаем 'LabelEncoder' на тренировочных метках 'y_train'.\n",
        "\"\"\"\n",
        "Важно, чтобы  'LabelEncoder'  был  обучен  только  на  тренировочных  данных  (используя  'le.fit(y_train)).\n",
        "Затем  можно  использовать  'le.transform()'  для  преобразования  тестовых  меток  'y_test'.\n",
        "Это  гарантирует,  что  тестовые  метки  будут  преобразованы  в  те же  числовые  значения,\n",
        "которые  были  использованы  для  тренировки  модели.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2APu6uS7wSu2"
      },
      "source": [
        "# 2.Обучение LightGBM или Сatboost на полученных векторах и подбор оптимальной комбинации гиперпараметров с помощью GridSearch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovPhMuAOhYeH"
      },
      "source": [
        "## 2.1.Сatboost + tf-idf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czp9ZmpOhYeH"
      },
      "source": [
        "Catboost дает хорошие результаты без подбора гиперпараметров, поэтому воспользуемся им."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1LPjaGM6hYeI"
      },
      "outputs": [],
      "source": [
        "#!pip freeze"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpVmQeM4mFr4",
        "outputId": "ee90f660-aee3-468f-c404-bf70ef22df16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.5-cp310-cp310-manylinux2014_x86_64.whl (98.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.25.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.0.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.5.0)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2j-ayRo6hYeI"
      },
      "outputs": [],
      "source": [
        "from catboost import CatBoostClassifier\n",
        "\n",
        "# инициализируем модель\n",
        "clf_cat = CatBoostClassifier(iterations=50, logging_level='Silent')\n",
        "\n",
        "# обучаем модель на тренировочных данных\n",
        "clf_cat.fit(X_train, le.transform(y_train));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UO1GTDBShYeI"
      },
      "outputs": [],
      "source": [
        "# делаем предсказание для тестовых данных\n",
        "y_pred = clf_cat.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGhG2ucXhYeI"
      },
      "outputs": [],
      "source": [
        "pred_proba = clf_cat.predict_proba(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gq1EPnVyhYeJ",
        "outputId": "3ccc5cfd-58c7-49f7-f65c-ba0a801bd64f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9364777333333333"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "roc_auc_score(y_test, pred_proba[:,1], average='macro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3Q7c_FbhYeJ",
        "outputId": "84cf0222-3f6b-48e9-c5e8-b271075ed1b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.84      0.86      7500\n",
            "           1       0.85      0.88      0.86      7500\n",
            "\n",
            "    accuracy                           0.86     15000\n",
            "   macro avg       0.86      0.86      0.86     15000\n",
            "weighted avg       0.86      0.86      0.86     15000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(le.transform(y_test), y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0DyQcxihYeJ"
      },
      "source": [
        "## 2.2. LightGBM + tf-idf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlJOWN9UhYeJ"
      },
      "source": [
        "### GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJMBbYAL3s9n",
        "outputId": "510dd6e3-ae25-4b5a-c8f0-906813876795"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
            "[CV 1/5; 1/27] START learning_rate=0.5, max_depth=-1, num_leaves=5..............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.660895 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71192\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22680\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 1/5; 1/27] END learning_rate=0.5, max_depth=-1, num_leaves=5;, score=0.863 total time=  11.1s\n",
            "[CV 2/5; 1/27] START learning_rate=0.5, max_depth=-1, num_leaves=5..............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.456640 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71580\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22831\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 2/5; 1/27] END learning_rate=0.5, max_depth=-1, num_leaves=5;, score=0.853 total time=  10.4s\n",
            "[CV 3/5; 1/27] START learning_rate=0.5, max_depth=-1, num_leaves=5..............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.679232 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 71405\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22764\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 3/5; 1/27] END learning_rate=0.5, max_depth=-1, num_leaves=5;, score=0.862 total time=  11.0s\n",
            "[CV 4/5; 1/27] START learning_rate=0.5, max_depth=-1, num_leaves=5..............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.451083 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 71138\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22691\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 4/5; 1/27] END learning_rate=0.5, max_depth=-1, num_leaves=5;, score=0.864 total time=  10.9s\n",
            "[CV 5/5; 1/27] START learning_rate=0.5, max_depth=-1, num_leaves=5..............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.521689 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71540\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22825\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 5/5; 1/27] END learning_rate=0.5, max_depth=-1, num_leaves=5;, score=0.864 total time=  10.6s\n",
            "[CV 1/5; 2/27] START learning_rate=0.5, max_depth=-1, num_leaves=15.............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.577112 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71192\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22680\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 1/5; 2/27] END learning_rate=0.5, max_depth=-1, num_leaves=15;, score=0.872 total time=  12.3s\n",
            "[CV 2/5; 2/27] START learning_rate=0.5, max_depth=-1, num_leaves=15.............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.571219 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 71580\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22831\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 2/5; 2/27] END learning_rate=0.5, max_depth=-1, num_leaves=15;, score=0.864 total time=  13.5s\n",
            "[CV 3/5; 2/27] START learning_rate=0.5, max_depth=-1, num_leaves=15.............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.753624 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71405\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22764\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 3/5; 2/27] END learning_rate=0.5, max_depth=-1, num_leaves=15;, score=0.875 total time=  14.4s\n",
            "[CV 4/5; 2/27] START learning_rate=0.5, max_depth=-1, num_leaves=15.............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.555037 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71138\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22691\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 4/5; 2/27] END learning_rate=0.5, max_depth=-1, num_leaves=15;, score=0.878 total time=  12.9s\n",
            "[CV 5/5; 2/27] START learning_rate=0.5, max_depth=-1, num_leaves=15.............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.761357 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71540\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22825\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 5/5; 2/27] END learning_rate=0.5, max_depth=-1, num_leaves=15;, score=0.880 total time=  13.6s\n",
            "[CV 1/5; 3/27] START learning_rate=0.5, max_depth=-1, num_leaves=31.............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.580269 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71192\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22680\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 1/5; 3/27] END learning_rate=0.5, max_depth=-1, num_leaves=31;, score=0.871 total time=  16.9s\n",
            "[CV 2/5; 3/27] START learning_rate=0.5, max_depth=-1, num_leaves=31.............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 2.446562 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71580\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22831\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 2/5; 3/27] END learning_rate=0.5, max_depth=-1, num_leaves=31;, score=0.867 total time=  18.0s\n",
            "[CV 3/5; 3/27] START learning_rate=0.5, max_depth=-1, num_leaves=31.............\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.920794 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71405\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22764\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 3/5; 3/27] END learning_rate=0.5, max_depth=-1, num_leaves=31;, score=0.879 total time=  20.2s\n",
            "[CV 4/5; 3/27] START learning_rate=0.5, max_depth=-1, num_leaves=31.............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.873984 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71138\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22691\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 4/5; 3/27] END learning_rate=0.5, max_depth=-1, num_leaves=31;, score=0.880 total time=  19.0s\n",
            "[CV 5/5; 3/27] START learning_rate=0.5, max_depth=-1, num_leaves=31.............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.614169 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71540\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22825\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 5/5; 3/27] END learning_rate=0.5, max_depth=-1, num_leaves=31;, score=0.872 total time=  18.8s\n",
            "[CV 1/5; 4/27] START learning_rate=0.5, max_depth=3, num_leaves=5...............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.645938 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71192\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22680\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 1/5; 4/27] END learning_rate=0.5, max_depth=3, num_leaves=5;, score=0.856 total time=  12.4s\n",
            "[CV 2/5; 4/27] START learning_rate=0.5, max_depth=3, num_leaves=5...............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.659045 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71580\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22831\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 2/5; 4/27] END learning_rate=0.5, max_depth=3, num_leaves=5;, score=0.846 total time=  11.3s\n",
            "[CV 3/5; 4/27] START learning_rate=0.5, max_depth=3, num_leaves=5...............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.880741 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 71405\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22764\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 3/5; 4/27] END learning_rate=0.5, max_depth=3, num_leaves=5;, score=0.865 total time=  11.7s\n",
            "[CV 4/5; 4/27] START learning_rate=0.5, max_depth=3, num_leaves=5...............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.616324 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71138\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22691\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 4/5; 4/27] END learning_rate=0.5, max_depth=3, num_leaves=5;, score=0.856 total time=  13.1s\n",
            "[CV 5/5; 4/27] START learning_rate=0.5, max_depth=3, num_leaves=5...............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.531165 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71540\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22825\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 5/5; 4/27] END learning_rate=0.5, max_depth=3, num_leaves=5;, score=0.859 total time=  12.1s\n",
            "[CV 1/5; 5/27] START learning_rate=0.5, max_depth=3, num_leaves=15..............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.546496 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71192\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22680\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[CV 1/5; 5/27] END learning_rate=0.5, max_depth=3, num_leaves=15;, score=0.853 total time=  11.4s\n",
            "[CV 2/5; 5/27] START learning_rate=0.5, max_depth=3, num_leaves=15..............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.525439 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71580\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22831\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[CV 2/5; 5/27] END learning_rate=0.5, max_depth=3, num_leaves=15;, score=0.845 total time=  12.7s\n",
            "[CV 3/5; 5/27] START learning_rate=0.5, max_depth=3, num_leaves=15..............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.912332 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71405\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22764\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[CV 3/5; 5/27] END learning_rate=0.5, max_depth=3, num_leaves=15;, score=0.858 total time=  12.1s\n",
            "[CV 4/5; 5/27] START learning_rate=0.5, max_depth=3, num_leaves=15..............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.595342 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71138\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22691\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[CV 4/5; 5/27] END learning_rate=0.5, max_depth=3, num_leaves=15;, score=0.858 total time=  11.0s\n",
            "[CV 5/5; 5/27] START learning_rate=0.5, max_depth=3, num_leaves=15..............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.888029 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 71540\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22825\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[CV 5/5; 5/27] END learning_rate=0.5, max_depth=3, num_leaves=15;, score=0.857 total time=  13.1s\n",
            "[CV 1/5; 6/27] START learning_rate=0.5, max_depth=3, num_leaves=31..............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.896808 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71192\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22680\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[CV 1/5; 6/27] END learning_rate=0.5, max_depth=3, num_leaves=31;, score=0.853 total time=  11.8s\n",
            "[CV 2/5; 6/27] START learning_rate=0.5, max_depth=3, num_leaves=31..............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.509561 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71580\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22831\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[CV 2/5; 6/27] END learning_rate=0.5, max_depth=3, num_leaves=31;, score=0.845 total time=  11.8s\n",
            "[CV 3/5; 6/27] START learning_rate=0.5, max_depth=3, num_leaves=31..............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.959590 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71405\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22764\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[CV 3/5; 6/27] END learning_rate=0.5, max_depth=3, num_leaves=31;, score=0.858 total time=  15.0s\n",
            "[CV 4/5; 6/27] START learning_rate=0.5, max_depth=3, num_leaves=31..............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 2.127566 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71138\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22691\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[CV 4/5; 6/27] END learning_rate=0.5, max_depth=3, num_leaves=31;, score=0.858 total time=  13.6s\n",
            "[CV 5/5; 6/27] START learning_rate=0.5, max_depth=3, num_leaves=31..............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.826834 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71540\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22825\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[CV 5/5; 6/27] END learning_rate=0.5, max_depth=3, num_leaves=31;, score=0.857 total time=  12.7s\n",
            "[CV 1/5; 7/27] START learning_rate=0.5, max_depth=7, num_leaves=5...............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.535767 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71192\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22680\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 1/5; 7/27] END learning_rate=0.5, max_depth=7, num_leaves=5;, score=0.863 total time=  13.0s\n",
            "[CV 2/5; 7/27] START learning_rate=0.5, max_depth=7, num_leaves=5...............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.544732 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71580\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22831\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 2/5; 7/27] END learning_rate=0.5, max_depth=7, num_leaves=5;, score=0.853 total time=  12.9s\n",
            "[CV 3/5; 7/27] START learning_rate=0.5, max_depth=7, num_leaves=5...............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.816685 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71405\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22764\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 3/5; 7/27] END learning_rate=0.5, max_depth=7, num_leaves=5;, score=0.862 total time=  12.4s\n",
            "[CV 4/5; 7/27] START learning_rate=0.5, max_depth=7, num_leaves=5...............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.490618 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71138\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22691\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 4/5; 7/27] END learning_rate=0.5, max_depth=7, num_leaves=5;, score=0.864 total time=  12.6s\n",
            "[CV 5/5; 7/27] START learning_rate=0.5, max_depth=7, num_leaves=5...............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.514714 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 71540\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22825\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5; 7/27] END learning_rate=0.5, max_depth=7, num_leaves=5;, score=0.864 total time=  12.8s\n",
            "[CV 1/5; 8/27] START learning_rate=0.5, max_depth=7, num_leaves=15..............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.820871 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71192\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22680\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[CV 1/5; 8/27] END learning_rate=0.5, max_depth=7, num_leaves=15;, score=0.863 total time=  13.9s\n",
            "[CV 2/5; 8/27] START learning_rate=0.5, max_depth=7, num_leaves=15..............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 2.124408 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 71580\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22831\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[CV 2/5; 8/27] END learning_rate=0.5, max_depth=7, num_leaves=15;, score=0.855 total time=  14.6s\n",
            "[CV 3/5; 8/27] START learning_rate=0.5, max_depth=7, num_leaves=15..............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 2.066428 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71405\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22764\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[CV 3/5; 8/27] END learning_rate=0.5, max_depth=7, num_leaves=15;, score=0.865 total time=  14.8s\n",
            "[CV 4/5; 8/27] START learning_rate=0.5, max_depth=7, num_leaves=15..............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.813083 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71138\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22691\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 4/5; 8/27] END learning_rate=0.5, max_depth=7, num_leaves=15;, score=0.866 total time=  12.7s\n",
            "[CV 5/5; 8/27] START learning_rate=0.5, max_depth=7, num_leaves=15..............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.688324 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71540\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22825\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[CV 5/5; 8/27] END learning_rate=0.5, max_depth=7, num_leaves=15;, score=0.873 total time=  13.2s\n",
            "[CV 1/5; 9/27] START learning_rate=0.5, max_depth=7, num_leaves=31..............\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 2.020852 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71192\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22680\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[CV 1/5; 9/27] END learning_rate=0.5, max_depth=7, num_leaves=31;, score=0.861 total time=  16.4s\n",
            "[CV 2/5; 9/27] START learning_rate=0.5, max_depth=7, num_leaves=31..............\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 2.190247 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71580\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22831\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[CV 2/5; 9/27] END learning_rate=0.5, max_depth=7, num_leaves=31;, score=0.849 total time=  13.7s\n",
            "[CV 3/5; 9/27] START learning_rate=0.5, max_depth=7, num_leaves=31..............\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.940455 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71405\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22764\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[CV 3/5; 9/27] END learning_rate=0.5, max_depth=7, num_leaves=31;, score=0.862 total time=  15.5s\n",
            "[CV 4/5; 9/27] START learning_rate=0.5, max_depth=7, num_leaves=31..............\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.725138 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 71138\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22691\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[CV 4/5; 9/27] END learning_rate=0.5, max_depth=7, num_leaves=31;, score=0.858 total time=  14.1s\n",
            "[CV 5/5; 9/27] START learning_rate=0.5, max_depth=7, num_leaves=31..............\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.790949 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71540\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22825\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[CV 5/5; 9/27] END learning_rate=0.5, max_depth=7, num_leaves=31;, score=0.859 total time=  14.5s\n",
            "[CV 1/5; 10/27] START learning_rate=0.1, max_depth=-1, num_leaves=5.............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 2.042665 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71192\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22680\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 1/5; 10/27] END learning_rate=0.1, max_depth=-1, num_leaves=5;, score=0.819 total time=  16.0s\n",
            "[CV 2/5; 10/27] START learning_rate=0.1, max_depth=-1, num_leaves=5.............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.626477 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71580\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22831\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 2/5; 10/27] END learning_rate=0.1, max_depth=-1, num_leaves=5;, score=0.806 total time=  14.0s\n",
            "[CV 3/5; 10/27] START learning_rate=0.1, max_depth=-1, num_leaves=5.............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.813627 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71405\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22764\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 3/5; 10/27] END learning_rate=0.1, max_depth=-1, num_leaves=5;, score=0.821 total time=  12.8s\n",
            "[CV 4/5; 10/27] START learning_rate=0.1, max_depth=-1, num_leaves=5.............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.002315 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 71138\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22691\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 4/5; 10/27] END learning_rate=0.1, max_depth=-1, num_leaves=5;, score=0.817 total time=  16.1s\n",
            "[CV 5/5; 10/27] START learning_rate=0.1, max_depth=-1, num_leaves=5.............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.749208 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 71540\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22825\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 5/5; 10/27] END learning_rate=0.1, max_depth=-1, num_leaves=5;, score=0.823 total time=  12.3s\n",
            "[CV 1/5; 11/27] START learning_rate=0.1, max_depth=-1, num_leaves=15............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.769125 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71192\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22680\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 1/5; 11/27] END learning_rate=0.1, max_depth=-1, num_leaves=15;, score=0.848 total time=  14.7s\n",
            "[CV 2/5; 11/27] START learning_rate=0.1, max_depth=-1, num_leaves=15............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 2.185106 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71580\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22831\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 2/5; 11/27] END learning_rate=0.1, max_depth=-1, num_leaves=15;, score=0.838 total time=  17.8s\n",
            "[CV 3/5; 11/27] START learning_rate=0.1, max_depth=-1, num_leaves=15............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 2.068368 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71405\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22764\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 3/5; 11/27] END learning_rate=0.1, max_depth=-1, num_leaves=15;, score=0.853 total time=  18.9s\n",
            "[CV 4/5; 11/27] START learning_rate=0.1, max_depth=-1, num_leaves=15............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 2.943311 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71138\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22691\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 4/5; 11/27] END learning_rate=0.1, max_depth=-1, num_leaves=15;, score=0.848 total time=  20.2s\n",
            "[CV 5/5; 11/27] START learning_rate=0.1, max_depth=-1, num_leaves=15............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 2.146612 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71540\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22825\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 5/5; 11/27] END learning_rate=0.1, max_depth=-1, num_leaves=15;, score=0.851 total time=  16.9s\n",
            "[CV 1/5; 12/27] START learning_rate=0.1, max_depth=-1, num_leaves=31............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.779932 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71192\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22680\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 1/5; 12/27] END learning_rate=0.1, max_depth=-1, num_leaves=31;, score=0.856 total time=  18.5s\n",
            "[CV 2/5; 12/27] START learning_rate=0.1, max_depth=-1, num_leaves=31............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.755083 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71580\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22831\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 2/5; 12/27] END learning_rate=0.1, max_depth=-1, num_leaves=31;, score=0.848 total time=  18.6s\n",
            "[CV 3/5; 12/27] START learning_rate=0.1, max_depth=-1, num_leaves=31............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 2.105406 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71405\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22764\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 3/5; 12/27] END learning_rate=0.1, max_depth=-1, num_leaves=31;, score=0.865 total time=  21.5s\n",
            "[CV 4/5; 12/27] START learning_rate=0.1, max_depth=-1, num_leaves=31............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.039851 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 71138\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22691\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 4/5; 12/27] END learning_rate=0.1, max_depth=-1, num_leaves=31;, score=0.859 total time=  28.0s\n",
            "[CV 5/5; 12/27] START learning_rate=0.1, max_depth=-1, num_leaves=31............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 2.104149 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71540\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22825\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 5/5; 12/27] END learning_rate=0.1, max_depth=-1, num_leaves=31;, score=0.865 total time=  20.7s\n",
            "[CV 1/5; 13/27] START learning_rate=0.1, max_depth=3, num_leaves=5..............\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.850012 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71192\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22680\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 1/5; 13/27] END learning_rate=0.1, max_depth=3, num_leaves=5;, score=0.814 total time=  13.6s\n",
            "[CV 2/5; 13/27] START learning_rate=0.1, max_depth=3, num_leaves=5..............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.671590 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71580\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22831\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 2/5; 13/27] END learning_rate=0.1, max_depth=3, num_leaves=5;, score=0.802 total time=  12.5s\n",
            "[CV 3/5; 13/27] START learning_rate=0.1, max_depth=3, num_leaves=5..............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.881391 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71405\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22764\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 3/5; 13/27] END learning_rate=0.1, max_depth=3, num_leaves=5;, score=0.811 total time=  12.5s\n",
            "[CV 4/5; 13/27] START learning_rate=0.1, max_depth=3, num_leaves=5..............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.531263 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 71138\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22691\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 4/5; 13/27] END learning_rate=0.1, max_depth=3, num_leaves=5;, score=0.810 total time=  12.6s\n",
            "[CV 5/5; 13/27] START learning_rate=0.1, max_depth=3, num_leaves=5..............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 2.011644 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71540\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22825\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 5/5; 13/27] END learning_rate=0.1, max_depth=3, num_leaves=5;, score=0.817 total time=  14.2s\n",
            "[CV 1/5; 14/27] START learning_rate=0.1, max_depth=3, num_leaves=15.............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.846718 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71192\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22680\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[CV 1/5; 14/27] END learning_rate=0.1, max_depth=3, num_leaves=15;, score=0.815 total time=  11.5s\n",
            "[CV 2/5; 14/27] START learning_rate=0.1, max_depth=3, num_leaves=15.............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.583197 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71580\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22831\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[CV 2/5; 14/27] END learning_rate=0.1, max_depth=3, num_leaves=15;, score=0.804 total time=  13.1s\n",
            "[CV 3/5; 14/27] START learning_rate=0.1, max_depth=3, num_leaves=15.............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 2.399040 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71405\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22764\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[CV 3/5; 14/27] END learning_rate=0.1, max_depth=3, num_leaves=15;, score=0.813 total time=  13.3s\n",
            "[CV 4/5; 14/27] START learning_rate=0.1, max_depth=3, num_leaves=15.............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.809077 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71138\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22691\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[CV 4/5; 14/27] END learning_rate=0.1, max_depth=3, num_leaves=15;, score=0.810 total time=  12.9s\n",
            "[CV 5/5; 14/27] START learning_rate=0.1, max_depth=3, num_leaves=15.............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.800459 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71540\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22825\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[CV 5/5; 14/27] END learning_rate=0.1, max_depth=3, num_leaves=15;, score=0.818 total time=  14.2s\n",
            "[CV 1/5; 15/27] START learning_rate=0.1, max_depth=3, num_leaves=31.............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.918563 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71192\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22680\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[CV 1/5; 15/27] END learning_rate=0.1, max_depth=3, num_leaves=31;, score=0.815 total time=  13.5s\n",
            "[CV 2/5; 15/27] START learning_rate=0.1, max_depth=3, num_leaves=31.............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.770747 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71580\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22831\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[CV 2/5; 15/27] END learning_rate=0.1, max_depth=3, num_leaves=31;, score=0.804 total time=  12.7s\n",
            "[CV 3/5; 15/27] START learning_rate=0.1, max_depth=3, num_leaves=31.............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.976753 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 71405\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22764\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[CV 3/5; 15/27] END learning_rate=0.1, max_depth=3, num_leaves=31;, score=0.813 total time=  13.6s\n",
            "[CV 4/5; 15/27] START learning_rate=0.1, max_depth=3, num_leaves=31.............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.624068 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71138\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22691\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[CV 4/5; 15/27] END learning_rate=0.1, max_depth=3, num_leaves=31;, score=0.810 total time=  12.9s\n",
            "[CV 5/5; 15/27] START learning_rate=0.1, max_depth=3, num_leaves=31.............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 2.229438 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71540\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22825\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[CV 5/5; 15/27] END learning_rate=0.1, max_depth=3, num_leaves=31;, score=0.818 total time=  13.8s\n",
            "[CV 1/5; 16/27] START learning_rate=0.1, max_depth=7, num_leaves=5..............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 2.848432 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 71192\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22680\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 1/5; 16/27] END learning_rate=0.1, max_depth=7, num_leaves=5;, score=0.819 total time=  17.1s\n",
            "[CV 2/5; 16/27] START learning_rate=0.1, max_depth=7, num_leaves=5..............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.706859 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71580\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22831\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 2/5; 16/27] END learning_rate=0.1, max_depth=7, num_leaves=5;, score=0.806 total time=  12.8s\n",
            "[CV 3/5; 16/27] START learning_rate=0.1, max_depth=7, num_leaves=5..............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.869759 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71405\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22764\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 3/5; 16/27] END learning_rate=0.1, max_depth=7, num_leaves=5;, score=0.821 total time=  13.4s\n",
            "[CV 4/5; 16/27] START learning_rate=0.1, max_depth=7, num_leaves=5..............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.535834 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71138\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22691\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 4/5; 16/27] END learning_rate=0.1, max_depth=7, num_leaves=5;, score=0.817 total time=  12.7s\n",
            "[CV 5/5; 16/27] START learning_rate=0.1, max_depth=7, num_leaves=5..............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.807351 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 71540\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22825\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 5/5; 16/27] END learning_rate=0.1, max_depth=7, num_leaves=5;, score=0.823 total time=  13.4s\n",
            "[CV 1/5; 17/27] START learning_rate=0.1, max_depth=7, num_leaves=15.............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.827957 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 71192\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22680\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 1/5; 17/27] END learning_rate=0.1, max_depth=7, num_leaves=15;, score=0.838 total time=  14.4s\n",
            "[CV 2/5; 17/27] START learning_rate=0.1, max_depth=7, num_leaves=15.............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.759114 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71580\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22831\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 2/5; 17/27] END learning_rate=0.1, max_depth=7, num_leaves=15;, score=0.829 total time=  14.7s\n",
            "[CV 3/5; 17/27] START learning_rate=0.1, max_depth=7, num_leaves=15.............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.945806 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 71405\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22764\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 3/5; 17/27] END learning_rate=0.1, max_depth=7, num_leaves=15;, score=0.841 total time=  14.9s\n",
            "[CV 4/5; 17/27] START learning_rate=0.1, max_depth=7, num_leaves=15.............\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 2.381058 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71138\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22691\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 4/5; 17/27] END learning_rate=0.1, max_depth=7, num_leaves=15;, score=0.836 total time=  16.1s\n",
            "[CV 5/5; 17/27] START learning_rate=0.1, max_depth=7, num_leaves=15.............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.910879 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71540\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22825\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 5/5; 17/27] END learning_rate=0.1, max_depth=7, num_leaves=15;, score=0.843 total time=  15.0s\n",
            "[CV 1/5; 18/27] START learning_rate=0.1, max_depth=7, num_leaves=31.............\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.926017 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 71192\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22680\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[CV 1/5; 18/27] END learning_rate=0.1, max_depth=7, num_leaves=31;, score=0.842 total time=  15.4s\n",
            "[CV 2/5; 18/27] START learning_rate=0.1, max_depth=7, num_leaves=31.............\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 2.090997 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71580\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22831\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[CV 2/5; 18/27] END learning_rate=0.1, max_depth=7, num_leaves=31;, score=0.829 total time=  16.1s\n",
            "[CV 3/5; 18/27] START learning_rate=0.1, max_depth=7, num_leaves=31.............\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 2.759777 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71405\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22764\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[CV 3/5; 18/27] END learning_rate=0.1, max_depth=7, num_leaves=31;, score=0.846 total time=  20.6s\n",
            "[CV 4/5; 18/27] START learning_rate=0.1, max_depth=7, num_leaves=31.............\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.658680 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71138\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22691\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[CV 4/5; 18/27] END learning_rate=0.1, max_depth=7, num_leaves=31;, score=0.836 total time=  14.0s\n",
            "[CV 5/5; 18/27] START learning_rate=0.1, max_depth=7, num_leaves=31.............\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 2.108155 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71540\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22825\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[CV 5/5; 18/27] END learning_rate=0.1, max_depth=7, num_leaves=31;, score=0.841 total time=  16.9s\n",
            "[CV 1/5; 19/27] START learning_rate=0.01, max_depth=-1, num_leaves=5............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 2.277216 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 71192\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22680\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 1/5; 19/27] END learning_rate=0.01, max_depth=-1, num_leaves=5;, score=0.734 total time=  14.8s\n",
            "[CV 2/5; 19/27] START learning_rate=0.01, max_depth=-1, num_leaves=5............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 2.109666 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 71580\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22831\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5; 19/27] END learning_rate=0.01, max_depth=-1, num_leaves=5;, score=0.731 total time=  14.3s\n",
            "[CV 3/5; 19/27] START learning_rate=0.01, max_depth=-1, num_leaves=5............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.876146 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71405\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22764\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 3/5; 19/27] END learning_rate=0.01, max_depth=-1, num_leaves=5;, score=0.742 total time=  13.3s\n",
            "[CV 4/5; 19/27] START learning_rate=0.01, max_depth=-1, num_leaves=5............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 2.333506 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71138\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22691\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 4/5; 19/27] END learning_rate=0.01, max_depth=-1, num_leaves=5;, score=0.738 total time=  14.7s\n",
            "[CV 5/5; 19/27] START learning_rate=0.01, max_depth=-1, num_leaves=5............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 2.102384 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71540\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22825\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 5/5; 19/27] END learning_rate=0.01, max_depth=-1, num_leaves=5;, score=0.741 total time=  12.4s\n",
            "[CV 1/5; 20/27] START learning_rate=0.01, max_depth=-1, num_leaves=15...........\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 2.096391 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71192\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22680\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 1/5; 20/27] END learning_rate=0.01, max_depth=-1, num_leaves=15;, score=0.761 total time=  15.0s\n",
            "[CV 2/5; 20/27] START learning_rate=0.01, max_depth=-1, num_leaves=15...........\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.811845 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71580\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22831\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 2/5; 20/27] END learning_rate=0.01, max_depth=-1, num_leaves=15;, score=0.753 total time=  16.5s\n",
            "[CV 3/5; 20/27] START learning_rate=0.01, max_depth=-1, num_leaves=15...........\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.710780 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71405\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22764\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 3/5; 20/27] END learning_rate=0.01, max_depth=-1, num_leaves=15;, score=0.767 total time=  15.9s\n",
            "[CV 4/5; 20/27] START learning_rate=0.01, max_depth=-1, num_leaves=15...........\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.768732 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71138\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22691\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 4/5; 20/27] END learning_rate=0.01, max_depth=-1, num_leaves=15;, score=0.762 total time=  14.6s\n",
            "[CV 5/5; 20/27] START learning_rate=0.01, max_depth=-1, num_leaves=15...........\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.942286 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71540\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22825\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 5/5; 20/27] END learning_rate=0.01, max_depth=-1, num_leaves=15;, score=0.759 total time=  15.7s\n",
            "[CV 1/5; 21/27] START learning_rate=0.01, max_depth=-1, num_leaves=31...........\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 2.071183 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71192\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22680\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 1/5; 21/27] END learning_rate=0.01, max_depth=-1, num_leaves=31;, score=0.774 total time=  18.6s\n",
            "[CV 2/5; 21/27] START learning_rate=0.01, max_depth=-1, num_leaves=31...........\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.938086 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71580\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22831\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 2/5; 21/27] END learning_rate=0.01, max_depth=-1, num_leaves=31;, score=0.759 total time=  17.8s\n",
            "[CV 3/5; 21/27] START learning_rate=0.01, max_depth=-1, num_leaves=31...........\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.824847 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71405\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22764\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 3/5; 21/27] END learning_rate=0.01, max_depth=-1, num_leaves=31;, score=0.777 total time=  19.1s\n",
            "[CV 4/5; 21/27] START learning_rate=0.01, max_depth=-1, num_leaves=31...........\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.673288 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71138\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22691\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 4/5; 21/27] END learning_rate=0.01, max_depth=-1, num_leaves=31;, score=0.774 total time=  17.8s\n",
            "[CV 5/5; 21/27] START learning_rate=0.01, max_depth=-1, num_leaves=31...........\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.932721 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71540\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22825\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 5/5; 21/27] END learning_rate=0.01, max_depth=-1, num_leaves=31;, score=0.768 total time=  17.0s\n",
            "[CV 1/5; 22/27] START learning_rate=0.01, max_depth=3, num_leaves=5.............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.575228 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71192\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22680\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 1/5; 22/27] END learning_rate=0.01, max_depth=3, num_leaves=5;, score=0.728 total time=  12.9s\n",
            "[CV 2/5; 22/27] START learning_rate=0.01, max_depth=3, num_leaves=5.............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 2.145790 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 71580\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22831\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 2/5; 22/27] END learning_rate=0.01, max_depth=3, num_leaves=5;, score=0.727 total time=  12.5s\n",
            "[CV 3/5; 22/27] START learning_rate=0.01, max_depth=3, num_leaves=5.............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.935394 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71405\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22764\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 3/5; 22/27] END learning_rate=0.01, max_depth=3, num_leaves=5;, score=0.736 total time=  12.4s\n",
            "[CV 4/5; 22/27] START learning_rate=0.01, max_depth=3, num_leaves=5.............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 2.639350 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 71138\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22691\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 4/5; 22/27] END learning_rate=0.01, max_depth=3, num_leaves=5;, score=0.736 total time=  16.3s\n",
            "[CV 5/5; 22/27] START learning_rate=0.01, max_depth=3, num_leaves=5.............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.587172 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71540\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22825\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 5/5; 22/27] END learning_rate=0.01, max_depth=3, num_leaves=5;, score=0.739 total time=  12.6s\n",
            "[CV 1/5; 23/27] START learning_rate=0.01, max_depth=3, num_leaves=15............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.909391 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 71192\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22680\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 1/5; 23/27] END learning_rate=0.01, max_depth=3, num_leaves=15;, score=0.731 total time=  12.6s\n",
            "[CV 2/5; 23/27] START learning_rate=0.01, max_depth=3, num_leaves=15............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.804185 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71580\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22831\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 2/5; 23/27] END learning_rate=0.01, max_depth=3, num_leaves=15;, score=0.731 total time=  13.7s\n",
            "[CV 3/5; 23/27] START learning_rate=0.01, max_depth=3, num_leaves=15............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.564977 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71405\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22764\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 3/5; 23/27] END learning_rate=0.01, max_depth=3, num_leaves=15;, score=0.738 total time=  12.4s\n",
            "[CV 4/5; 23/27] START learning_rate=0.01, max_depth=3, num_leaves=15............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.818415 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71138\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22691\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[CV 4/5; 23/27] END learning_rate=0.01, max_depth=3, num_leaves=15;, score=0.737 total time=  11.1s\n",
            "[CV 5/5; 23/27] START learning_rate=0.01, max_depth=3, num_leaves=15............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.941217 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 71540\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22825\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[CV 5/5; 23/27] END learning_rate=0.01, max_depth=3, num_leaves=15;, score=0.740 total time=  13.5s\n",
            "[CV 1/5; 24/27] START learning_rate=0.01, max_depth=3, num_leaves=31............\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.903086 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 71192\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22680\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 1/5; 24/27] END learning_rate=0.01, max_depth=3, num_leaves=31;, score=0.731 total time=  12.1s\n",
            "[CV 2/5; 24/27] START learning_rate=0.01, max_depth=3, num_leaves=31............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.688734 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71580\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22831\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 2/5; 24/27] END learning_rate=0.01, max_depth=3, num_leaves=31;, score=0.731 total time=  12.3s\n",
            "[CV 3/5; 24/27] START learning_rate=0.01, max_depth=3, num_leaves=31............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.627706 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 71405\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22764\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 3/5; 24/27] END learning_rate=0.01, max_depth=3, num_leaves=31;, score=0.738 total time=  13.1s\n",
            "[CV 4/5; 24/27] START learning_rate=0.01, max_depth=3, num_leaves=31............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 2.126219 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71138\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22691\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[CV 4/5; 24/27] END learning_rate=0.01, max_depth=3, num_leaves=31;, score=0.737 total time=  13.6s\n",
            "[CV 5/5; 24/27] START learning_rate=0.01, max_depth=3, num_leaves=31............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.698015 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71540\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22825\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[CV 5/5; 24/27] END learning_rate=0.01, max_depth=3, num_leaves=31;, score=0.740 total time=  11.3s\n",
            "[CV 1/5; 25/27] START learning_rate=0.01, max_depth=7, num_leaves=5.............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.846950 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71192\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22680\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 1/5; 25/27] END learning_rate=0.01, max_depth=7, num_leaves=5;, score=0.734 total time=  13.4s\n",
            "[CV 2/5; 25/27] START learning_rate=0.01, max_depth=7, num_leaves=5.............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 2.012908 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71580\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22831\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 2/5; 25/27] END learning_rate=0.01, max_depth=7, num_leaves=5;, score=0.731 total time=  12.8s\n",
            "[CV 3/5; 25/27] START learning_rate=0.01, max_depth=7, num_leaves=5.............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.993323 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 71405\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22764\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 3/5; 25/27] END learning_rate=0.01, max_depth=7, num_leaves=5;, score=0.742 total time=  11.9s\n",
            "[CV 4/5; 25/27] START learning_rate=0.01, max_depth=7, num_leaves=5.............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.890168 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71138\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22691\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 4/5; 25/27] END learning_rate=0.01, max_depth=7, num_leaves=5;, score=0.738 total time=  14.0s\n",
            "[CV 5/5; 25/27] START learning_rate=0.01, max_depth=7, num_leaves=5.............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 2.076271 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 71540\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22825\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 5/5; 25/27] END learning_rate=0.01, max_depth=7, num_leaves=5;, score=0.741 total time=  14.2s\n",
            "[CV 1/5; 26/27] START learning_rate=0.01, max_depth=7, num_leaves=15............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.850504 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71192\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22680\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 1/5; 26/27] END learning_rate=0.01, max_depth=7, num_leaves=15;, score=0.762 total time=  14.3s\n",
            "[CV 2/5; 26/27] START learning_rate=0.01, max_depth=7, num_leaves=15............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.763364 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71580\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22831\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 2/5; 26/27] END learning_rate=0.01, max_depth=7, num_leaves=15;, score=0.750 total time=  14.1s\n",
            "[CV 3/5; 26/27] START learning_rate=0.01, max_depth=7, num_leaves=15............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.862086 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71405\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22764\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 3/5; 26/27] END learning_rate=0.01, max_depth=7, num_leaves=15;, score=0.768 total time=  15.3s\n",
            "[CV 4/5; 26/27] START learning_rate=0.01, max_depth=7, num_leaves=15............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 2.747465 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71138\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22691\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 4/5; 26/27] END learning_rate=0.01, max_depth=7, num_leaves=15;, score=0.762 total time=  17.5s\n",
            "[CV 5/5; 26/27] START learning_rate=0.01, max_depth=7, num_leaves=15............\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 2.092257 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71540\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22825\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[CV 5/5; 26/27] END learning_rate=0.01, max_depth=7, num_leaves=15;, score=0.759 total time=  17.0s\n",
            "[CV 1/5; 27/27] START learning_rate=0.01, max_depth=7, num_leaves=31............\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.854306 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71192\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22680\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[CV 1/5; 27/27] END learning_rate=0.01, max_depth=7, num_leaves=31;, score=0.768 total time=  16.0s\n",
            "[CV 2/5; 27/27] START learning_rate=0.01, max_depth=7, num_leaves=31............\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.857082 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71580\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22831\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[CV 2/5; 27/27] END learning_rate=0.01, max_depth=7, num_leaves=31;, score=0.757 total time=  15.5s\n",
            "[CV 3/5; 27/27] START learning_rate=0.01, max_depth=7, num_leaves=31............\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.661785 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 71405\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22764\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[CV 3/5; 27/27] END learning_rate=0.01, max_depth=7, num_leaves=31;, score=0.773 total time=  15.7s\n",
            "[CV 4/5; 27/27] START learning_rate=0.01, max_depth=7, num_leaves=31............\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 2.586085 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 71138\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22691\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[CV 4/5; 27/27] END learning_rate=0.01, max_depth=7, num_leaves=31;, score=0.765 total time=  19.0s\n",
            "[CV 5/5; 27/27] START learning_rate=0.01, max_depth=7, num_leaves=31............\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 14000, number of negative: 14000\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.904008 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 71540\n",
            "[LightGBM] [Info] Number of data points in the train set: 28000, number of used features: 22825\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[CV 5/5; 27/27] END learning_rate=0.01, max_depth=7, num_leaves=31;, score=0.766 total time=  18.0s\n",
            "[LightGBM] [Info] Number of positive: 17500, number of negative: 17500\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 4.626747 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 87186\n",
            "[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 28140\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "CPU times: total: 1h 30min 30s\n",
            "Wall time: 33min 16s\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=LGBMClassifier(random_state=123),\n",
              "             param_grid={&#x27;learning_rate&#x27;: [0.5, 0.1, 0.01],\n",
              "                         &#x27;max_depth&#x27;: [-1, 3, 7], &#x27;num_leaves&#x27;: [5, 15, 31]},\n",
              "             scoring=&#x27;f1&#x27;, verbose=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=LGBMClassifier(random_state=123),\n",
              "             param_grid={&#x27;learning_rate&#x27;: [0.5, 0.1, 0.01],\n",
              "                         &#x27;max_depth&#x27;: [-1, 3, 7], &#x27;num_leaves&#x27;: [5, 15, 31]},\n",
              "             scoring=&#x27;f1&#x27;, verbose=10)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(random_state=123)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(random_state=123)</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "GridSearchCV(estimator=LGBMClassifier(random_state=123),\n",
              "             param_grid={'learning_rate': [0.5, 0.1, 0.01],\n",
              "                         'max_depth': [-1, 3, 7], 'num_leaves': [5, 15, 31]},\n",
              "             scoring='f1', verbose=10)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "%%time\n",
        "\n",
        "model = LGBMClassifier(random_state=42)\n",
        "params = {\n",
        "    'num_leaves': [5, 15, 31], # default=31\n",
        "    'max_depth': [-1, 3, 7], # default=-1\n",
        "    'learning_rate': [0.5, 0.1, 0.01], # default=0.1\n",
        "}\n",
        "\n",
        "clf = GridSearchCV(model, params, scoring='f1', verbose=10)\n",
        "clf.fit(X_train, le.transform(y_train))\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuRl3USYIRH3",
        "outputId": "ad3cb6f9-6ead-4be2-bd3d-27c1069b1a8d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'learning_rate': 0.5, 'max_depth': -1, 'num_leaves': 15}"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "clf.best_params_\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5y_mZvfPez4L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1257d011-12f3-4172-92bb-8c10c00f2f55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17500, number of negative: 17500\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 39.125274 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 87186\n",
            "[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 28140\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
          ]
        }
      ],
      "source": [
        "# Обновим модель после фиттинга\n",
        "\n",
        "# инициализируем модель с подобранными гиперпараметрами\n",
        "clf = LGBMClassifier(**{'learning_rate': 0.5, 'max_depth': -1, 'num_leaves': 15}, random_state=42)\n",
        "\n",
        "# обучаем модель на тренировочных данных\n",
        "clf.fit(X_train, le.transform(y_train));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2zhv8wsfr6j"
      },
      "outputs": [],
      "source": [
        "# делаем предсказание для тестовых данных\n",
        "y_pred = clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHGWk8QhhYeQ"
      },
      "outputs": [],
      "source": [
        "pred_proba = clf.predict_proba(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lULBJjZMhYeQ",
        "outputId": "6ef47a86-4170-46ee-fe21-6b8ea1e2dbb2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9483703466666665"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "roc_auc_score(le.transform(y_test), pred_proba[:,1], average='macro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p64NaX8DfgKb",
        "outputId": "aa10bcc3-04ce-4169-d20f-db6d0fb629f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.87      0.87      7500\n",
            "           1       0.87      0.88      0.88      7500\n",
            "\n",
            "    accuracy                           0.88     15000\n",
            "   macro avg       0.88      0.88      0.88     15000\n",
            "weighted avg       0.88      0.88      0.88     15000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(le.transform(y_test), y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7W00SQohYeR"
      },
      "source": [
        "precision    recall  f1-score   support\n",
        "\n",
        "           0       0.88      0.87      0.87      7500\n",
        "           1       0.87      0.88      0.88      7500\n",
        "\n",
        "    accuracy                           0.88     15000\n",
        "   macro avg       0.88      0.88      0.88     15000\n",
        "weighted avg       0.88      0.88      0.88     15000\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGOVuKNJhYeR"
      },
      "source": [
        "# 3. Воспользуемся предобученными fasttext эмбеддингами для векторизации текста"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohrGnZVChYeR"
      },
      "source": [
        "Будем использовать FastText как более современный и эффективный по сравнению с word2vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9ezWKCvTY_0"
      },
      "source": [
        "## 3.1. Fasttext pre-trained emb  + LGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYluIYpEPCrI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "616937f4-d340-42f7-bbcc-e621f174bb8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.3.tar.gz (73 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/73.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m71.7/73.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2 (from fasttext)\n",
            "  Using cached pybind11-2.13.1-py3-none-any.whl (238 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext) (1.25.2)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.3-cp310-cp310-linux_x86_64.whl size=4246764 sha256=836c3f7b605ca3dc7396654bbb48bcaf7606409bd3559def9ca36e677e30d209\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/a2/00/81db54d3e6a8199b829d58e02cec2ddb20ce3e59fad8d3c92a\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.3 pybind11-2.13.1\n"
          ]
        }
      ],
      "source": [
        "!pip install fasttext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rotz90vvhYeS"
      },
      "source": [
        "# Выбор модели\n",
        "Я выбирала между моделями:\n",
        "1) facebook/fasttext-en-vectors (https://huggingface.co/facebook/fasttext-en-vectors) c параметрами: cosine_similarity(\"man\", \"boy\") =\n",
        "0.0616533\n",
        "2) cc.en.300.bin.gz (https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz), хорошо описанную на сайте: https://programmersought.com/article/457510884978/83"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8BOG_7R0X2Cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9103a2eb-69fa-4316-fcd8-59fe7025fff8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-07-15 14:21:08--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 18.165.83.35, 18.165.83.91, 18.165.83.44, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|18.165.83.35|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4503593528 (4.2G) [application/octet-stream]\n",
            "Saving to: ‘cc.en.300.bin.gz’\n",
            "\n",
            "cc.en.300.bin.gz    100%[===================>]   4.19G  7.15MB/s    in 5m 59s  \n",
            "\n",
            "2024-07-15 14:27:08 (12.0 MB/s) - ‘cc.en.300.bin.gz’ saved [4503593528/4503593528]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Скачаем файл с предварительно обученными векторами слов для английского языка.\n",
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYIHebiAX2_i"
      },
      "outputs": [],
      "source": [
        "# Распакуем файл bin.gz в текущую папку, -d сохранить оригинал (-Keep):\n",
        "!gzip -d /content/cc.en.300.bin.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1SY8FLpHTbGl"
      },
      "outputs": [],
      "source": [
        "# Загрузим модель\n",
        "import fasttext\n",
        "ft = fasttext.load_model('cc.en.300.bin')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(ft.get_words())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20pdauIHqHIR",
        "outputId": "85618150-7a80-41b6-956c-517add5a98ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000000"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "m01x4B0ShzPh",
        "outputId": "895c75b5-9343-4eb6-ddb0-12fb13f9451f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-939bc68a699d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clear'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sentence_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ],
      "source": [
        "# Преобразуем текстовые данные из столбца `'clear'` DataFrame `df` в векторы эмбеддингов, используя модель FastText `ft`\n",
        "embeddings = df['clear'].progress_apply(ft.get_sentence_vector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCajUTVyux-3",
        "outputId": "5e4d1143-97c9-4619-dec0-9f20a24944cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embeddings[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Уменьшение размерности с помощью PCA\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=100)  # Установка желаемого количества компонент\n",
        "reduced_embeddings = pca.fit_transform(embeddings)"
      ],
      "metadata": {
        "id": "vn2GZPNxtnQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание новой модели FastText с уменьшенными эмбеддингами\n",
        "new_ft = fasttext.FastText(\n",
        "    input=reduced_embeddings,\n",
        "    output='cc.en.100.bin',  # Имя для сохранения новой модели\n",
        "    dim=100,  # Новое измерение эмбеддингов\n",
        "    model='skipgram',  # Тип модели (может быть 'skipgram' или 'cbow')\n",
        ")\n",
        "\n",
        "# Сохранение новой модели\n",
        "new_ft.save_model('cc.en.100.bin')"
      ],
      "metadata": {
        "id": "WKNK3Bwatnd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvqmSIZjYzuk",
        "outputId": "33fe43f0-eb7a-4780-9215-6557bc1e4977"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000000"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "len(ft.get_words())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = df['clear'].progress_apply(ft.get_sentence_vector)"
      ],
      "metadata": {
        "id": "j-7772FQyObM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings[0].shape"
      ],
      "metadata": {
        "id": "FS81BF5lyP3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQwui7hhkVCN"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(np.array(embeddings.tolist()), df['sentiment'], test_size=0.3, random_state=42, stratify=df['sentiment'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EkizCKs6kgUe"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "model = LGBMClassifier(random_state=123)\n",
        "params = {\n",
        "    'num_leaves': [5, 15, 31], # default=31\n",
        "    'max_depth': [-1, 3, 7], # default=-1\n",
        "    'learning_rate': [0.5, 0.1, 0.01], # default=0.1\n",
        "}\n",
        "\n",
        "clf = GridSearchCV(model, params, scoring='f1', verbose=10)\n",
        "clf.fit(X_train, le.transform(y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qqd0_y8-pFei",
        "outputId": "07ac7fe9-04bd-4108-935b-0376d1a44bf5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'learning_rate': 0.1, 'max_depth': 7, 'num_leaves': 31}"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0Rjf76AqKPB",
        "outputId": "95452f31-c7a8-4e9f-e258-573e3e540609"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.84      0.84      7500\n",
            "           1       0.84      0.85      0.84      7500\n",
            "\n",
            "    accuracy                           0.84     15000\n",
            "   macro avg       0.84      0.84      0.84     15000\n",
            "weighted avg       0.84      0.84      0.84     15000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred = clf.predict(X_test)\n",
        "print(classification_report(le.transform(y_test), y_pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}